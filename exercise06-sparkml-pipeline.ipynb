{"cells":[{"cell_type":"markdown","source":["# Exercise 06 : SparkML Pipeline\nHere we implement machine learning tasks with **SparkML pipeline**. We create the model to predict the flight delay over 15 minutes (ARR_DEL15) using other attributes (airport code, career, weather conditions, etc).\n\nBefore starting, you must put [flight_weather.csv](https://1drv.ms/u/s!AuopXnMb-Aqcgalq5Tp4UP7W1eJsRg) in your blob container. (See \"Exercise 05 : Working with Azure services\")"],"metadata":{}},{"cell_type":"code","source":["# Read dataset from Azure Blob\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\ndf = (sqlContext.read.format(\"csv\").\n  option(\"header\", \"true\").\n  option(\"nullValue\", \"NA\").\n  option(\"inferSchema\", True).\n  load(\"wasbs://container01@demostore01.blob.core.windows.net/flight_weather.csv\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Select required columns\ndf = df.select(\n  \"ARR_DEL15\",\n  \"MONTH\",\n  \"DAY_OF_WEEK\",\n  \"UNIQUE_CARRIER\",\n  \"ORIGIN\",\n  \"DEST\",\n  \"CRS_DEP_TIME\",\n  \"CRS_ARR_TIME\",\n  \"RelativeHumidityOrigin\",\n  \"AltimeterOrigin\",\n  \"DryBulbCelsiusOrigin\",\n  \"WindSpeedOrigin\",\n  \"VisibilityOrigin\",\n  \"DewPointCelsiusOrigin\",\n  \"RelativeHumidityDest\",\n  \"AltimeterDest\",\n  \"DryBulbCelsiusDest\",\n  \"WindSpeedDest\",\n  \"VisibilityDest\",\n  \"DewPointCelsiusDest\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Drop rows with null values\ndf = df.dropna()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Split data into train data and test data\n(traindf, testdf) = df.randomSplit([0.8, 0.2])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Convert categorical values to indexer (0, 1, ...)\nfrom pyspark.ml.feature import StringIndexer\nuniqueCarrierIndexer = StringIndexer(inputCol=\"UNIQUE_CARRIER\", outputCol=\"Indexed_UNIQUE_CARRIER\").fit(df)\noriginIndexer = StringIndexer(inputCol=\"ORIGIN\", outputCol=\"Indexed_ORIGIN\").fit(df)\ndestIndexer = StringIndexer(inputCol=\"DEST\", outputCol=\"Indexed_DEST\").fit(df)\narrDel15Indexer = StringIndexer(inputCol=\"ARR_DEL15\", outputCol=\"Indexed_ARR_DEL15\").fit(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Assemble feature columns\nfrom pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(\n  inputCols = [\n    \"MONTH\",\n    \"DAY_OF_WEEK\",\n    \"Indexed_UNIQUE_CARRIER\",\n    \"Indexed_ORIGIN\",\n    \"Indexed_DEST\",\n    \"CRS_DEP_TIME\",\n    \"CRS_ARR_TIME\",\n    \"RelativeHumidityOrigin\",\n    \"AltimeterOrigin\",\n    \"DryBulbCelsiusOrigin\",\n    \"WindSpeedOrigin\",\n    \"VisibilityOrigin\",\n    \"DewPointCelsiusOrigin\",\n    \"RelativeHumidityDest\",\n    \"AltimeterDest\",\n    \"DryBulbCelsiusDest\",\n    \"WindSpeedDest\",\n    \"VisibilityDest\",\n    \"DewPointCelsiusDest\"],\n  outputCol = \"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Classify\nfrom pyspark.ml.classification import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"ARR_DEL15\", maxDepth=15, maxBins=500)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Create pipeline and Train\nfrom pyspark.ml import Pipeline\npipeline = Pipeline(stages=[uniqueCarrierIndexer, originIndexer, destIndexer, arrDel15Indexer, assembler, classifier])\nmodel = pipeline.fit(traindf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Predict test data\npred = model.transform(testdf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Evaluate results\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(labelCol=\"ARR_DEL15\", predictionCol=\"prediction\")\naccuracy = evaluator.evaluate(pred)\nprint(\"Accuracy = %g\" % accuracy)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.786826\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":12}],"metadata":{"name":"exercise06-sparkml-pipeline","notebookId":3356844856711711},"nbformat":4,"nbformat_minor":0}
